# üîç Searchable PDF Q&A ‚Äî MiniLM + Gemma2:2B

This project demonstrates a **local PDF-based question-answering system** using **LangChain**, **local embeddings**, and optionally **Gemma2** for generating responses. Users can ask questions, and the system retrieves the most relevant text chunks from PDFs and provides an answer along with the context used.

---

## **Features**

- Extract text from PDF documents and split it into meaningful chunks.
- Convert chunks into embeddings and store them in a **local Chroma vector database**.
- Query the vector database with natural language questions.
- Retrieve the most relevant chunks based on similarity search.
- Show the answer and the context used.
- Display query response time.
- Optionally use **Gemma2:2B** for AI-generated answers (fits modest GPUs).

---

## **Tech Stack**

- **Python 3.10+**
- **Streamlit** ‚Äî Web UI
- **LangChain** ‚Äî Orchestration & vectorstore integration
- **Chroma** ‚Äî Local vector database
- **HuggingFace MiniLM** ‚Äî Lightweight local embeddings (384D)
- **Gemma2 (optional)** ‚Äî Local LLM for responses
- **PyPDF** ‚Äî PDF text extraction

---

## **Setup Instructions**

1. **Clone the repository**:
    ```bash
    git clone https://github.com/Akarsh-2004/tasks
    cd task1
    ```

2. **Create a virtual environment** (recommended):
    ```bash
    python -m venv venv
    source venv/bin/activate   # Linux/Mac
    venv\Scripts\activate      # Windows
    ```

3. **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```
    download ollama or you can use cloud  based AI APIs I have used Ollama cuz its free
    ```
    ollama serve
    ollama pull gemma2:2b

   ```
4. **Place the PDF files** in the project directory:
    - `2506.02153v2.pdf`
    - `reasoning_models_paper.pdf`

5. **Build the vector database**:
    ```bash
    python build_db.py
    ```

6. **Run the Streamlit app**:
    ```bash
    streamlit run app.py
    ```

7. **Open the interface** in your browser and ask questions about the PDFs.

---

## **Usage**

1. Enter your question in the text box.
2. Click **Search**.
3. The system displays:
    - **Answer** (generated by Gemma2 or local embeddings)
    - **Relevant PDF chunks**
    - **Query response time**

---


<img width="1919" height="964" alt="Screenshot 2025-11-12 110729" src="https://github.com/user-attachments/assets/59a2c62c-cb88-45db-986d-e6c901e54057" />

<img width="1919" height="878" alt="Screenshot 2025-11-12 110739" src="https://github.com/user-attachments/assets/a5d44fab-6440-4b78-a8c5-5e2092eca466" />

<img width="1919" height="775" alt="Screenshot 2025-11-12 110747" src="https://github.com/user-attachments/assets/ecfd692c-64f0-4009-8562-e6a96bb4407f" />

**Author:** Akarsh Saklani  
**Date:** November 2025
